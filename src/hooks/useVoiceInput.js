import { useState, useRef, useCallback } from 'react';

// ç™¾åº¦è¯­éŸ³è¯†åˆ« API é…ç½®
const BAIDU_API_KEY = 'j0xBgZAd65ydvM9zO36SqNmL';
const BAIDU_SECRET_KEY = 'Q0KztLX8lcIUu6JpzWVEx8MwgnbgW6EL';

// ç¼“å­˜ access_token
let cachedToken = null;
let tokenExpireTime = 0;

// è·å–ç™¾åº¦ access_tokenï¼ˆå¸¦ç¼“å­˜ï¼‰
const getBaiduAccessToken = async () => {
    // å¦‚æœ token è¿˜æœ‰æ•ˆï¼Œç›´æ¥è¿”å›
    if (cachedToken && Date.now() < tokenExpireTime) {
        return cachedToken;
    }

    const tokenUrl = `/baidu-token?grant_type=client_credentials&client_id=${BAIDU_API_KEY}&client_secret=${BAIDU_SECRET_KEY}`;

    try {
        const response = await fetch(tokenUrl, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'Accept': 'application/json'
            }
        });
        const data = await response.json();
        if (data.access_token) {
            cachedToken = data.access_token;
            // token æœ‰æ•ˆæœŸ 30 å¤©ï¼Œæˆ‘ä»¬è®¾ç½® 29 å¤©åè¿‡æœŸ
            tokenExpireTime = Date.now() + (29 * 24 * 60 * 60 * 1000);
            return cachedToken;
        }
        throw new Error(data.error_description || 'è·å– token å¤±è´¥');
    } catch (error) {
        console.error('è·å–ç™¾åº¦ access_token å¤±è´¥:', error);
        throw error;
    }
};

// å°† Float32Array è½¬æ¢ä¸º 16-bit PCM
const floatTo16BitPCM = (float32Array) => {
    const pcm16 = new Int16Array(float32Array.length);
    for (let i = 0; i < float32Array.length; i++) {
        const s = Math.max(-1, Math.min(1, float32Array[i]));
        pcm16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
    }
    return pcm16;
};

// å°† ArrayBuffer è½¬æ¢ä¸º base64
const arrayBufferToBase64 = (buffer) => {
    const bytes = new Uint8Array(buffer);
    let binary = '';
    for (let i = 0; i < bytes.byteLength; i++) {
        binary += String.fromCharCode(bytes[i]);
    }
    return btoa(binary);
};

// è°ƒç”¨ç™¾åº¦è¯­éŸ³è¯†åˆ« API
const recognizeSpeech = async (pcmData, accessToken) => {
    const base64Audio = arrayBufferToBase64(pcmData.buffer);
    const audioLen = pcmData.buffer.byteLength;

    console.log('=== ç™¾åº¦è¯­éŸ³è¯†åˆ«è°ƒè¯•ä¿¡æ¯ ===');
    console.log('PCM æ•°æ®å­—èŠ‚æ•°:', audioLen);
    console.log('Base64 é•¿åº¦:', base64Audio.length);

    const requestBody = {
        format: 'pcm',
        rate: 16000,
        channel: 1,
        cuid: 'golf_frontend_' + Math.random().toString(36).substr(2, 9),
        token: accessToken,
        speech: base64Audio,
        len: audioLen,
        dev_pid: 1537  // 1537=æ™®é€šè¯(æ”¯æŒç®€å•çš„è‹±æ–‡è¯†åˆ«), 1737=è‹±è¯­, 1637=ç²¤è¯­
    };

    try {
        const response = await fetch('/baidu-asr', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json'
            },
            body: JSON.stringify(requestBody)
        });

        const data = await response.json();
        console.log('=== ç™¾åº¦ API å®Œæ•´è¿”å› ===');
        console.log(JSON.stringify(data, null, 2));

        if (data.err_no === 0 && data.result && data.result.length > 0) {
            console.log('âœ… è¯†åˆ«æˆåŠŸ:', data.result[0]);
            return data.result[0];
        } else {
            console.error('âŒ è¯†åˆ«å¤±è´¥ï¼Œé”™è¯¯ç :', data.err_no, 'é”™è¯¯ä¿¡æ¯:', data.err_msg);
            const errorMessages = {
                3300: 'è¾“å…¥å‚æ•°ä¸æ­£ç¡®',
                3301: 'éŸ³é¢‘è´¨é‡è¿‡å·®',
                3302: 'é‰´æƒå¤±è´¥',
                3303: 'è¯­éŸ³æœåŠ¡å™¨åç«¯é—®é¢˜',
                3304: 'ç”¨æˆ·çš„è¯·æ±‚QPSè¶…é™',
                3305: 'ç”¨æˆ·çš„æ—¥pvè¶…é™',
                3307: 'è¯­éŸ³æœåŠ¡å™¨åç«¯è¯†åˆ«å‡ºé”™é—®é¢˜',
                3308: 'éŸ³é¢‘è¿‡é•¿',
                3309: 'éŸ³é¢‘æ•°æ®é—®é¢˜',
                3310: 'è¾“å…¥çš„éŸ³é¢‘æ–‡ä»¶è¿‡å¤§',
                3311: 'é‡‡æ ·ç‡rateå‚æ•°ä¸åœ¨é€‰é¡¹é‡Œ',
                3312: 'éŸ³é¢‘æ ¼å¼formatå‚æ•°ä¸åœ¨é€‰é¡¹é‡Œ'
            };
            throw new Error(errorMessages[data.err_no] || `è¯†åˆ«å¤±è´¥ (${data.err_no}): ${data.err_msg || 'æœªçŸ¥é”™è¯¯'}`);
        }
    } catch (error) {
        console.error('ç™¾åº¦è¯­éŸ³è¯†åˆ«å¤±è´¥:', error);
        throw error;
    }
};

export const useVoiceInput = () => {
    const [isListening, setIsListening] = useState(false);
    const [hasSupport, setHasSupport] = useState(true);
    const streamRef = useRef(null);
    const onResultCallbackRef = useRef(null);
    const timeoutRef = useRef(null);
    const audioContextRef = useRef(null);
    const processorRef = useRef(null);
    const sourceRef = useRef(null);
    const audioChunksRef = useRef([]);
    const actualSampleRateRef = useRef(0);
    const segmentIntervalRef = useRef(null);
    const lastProcessedIndexRef = useRef(0);

    // æ£€æŸ¥æµè§ˆå™¨æ˜¯å¦æ”¯æŒå¿…è¦çš„ API
    useState(() => {
        if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
            setHasSupport(false);
        }
    });

    // å¤„ç†å½“å‰ç´¯ç§¯çš„éŸ³é¢‘æ•°æ®ï¼ˆç”¨äºåˆ†æ®µè¯†åˆ«ï¼‰
    const processCurrentSegment = useCallback(async (isPartial = true) => {
        const totalChunks = audioChunksRef.current.length;
        const lastProcessedIndex = lastProcessedIndexRef.current;

        // å¦‚æœæ²¡æœ‰æ–°çš„æ•°æ®å—ï¼Œè·³è¿‡
        if (totalChunks <= lastProcessedIndex) {
            return;
        }

        const audioChunks = audioChunksRef.current;
        const actualSampleRate = actualSampleRateRef.current;

        // åˆå¹¶æ‰€æœ‰éŸ³é¢‘æ•°æ®ï¼ˆåŒ…æ‹¬å·²å¤„ç†çš„ï¼‰
        const totalLength = audioChunks.reduce((acc, chunk) => acc + chunk.length, 0);
        const mergedAudio = new Float32Array(totalLength);
        let offset = 0;
        for (const chunk of audioChunks) {
            mergedAudio.set(chunk, offset);
            offset += chunk.length;
        }

        const duration = totalLength / actualSampleRate;

        // è‡³å°‘éœ€è¦ 0.5 ç§’æ‰è¿›è¡Œè¯†åˆ«
        if (duration < 0.5) {
            return;
        }

        console.log(`${isPartial ? 'ğŸ“ åˆ†æ®µ' : 'ğŸ¯ æœ€ç»ˆ'}è¯†åˆ«: ${duration.toFixed(2)}ç§’éŸ³é¢‘`);

        try {
            // é‡é‡‡æ ·åˆ° 16000Hz
            const targetSampleRate = 16000;
            const ratio = actualSampleRate / targetSampleRate;
            const newLength = Math.round(totalLength / ratio);
            const resampled = new Float32Array(newLength);

            for (let i = 0; i < newLength; i++) {
                const srcIndex = i * ratio;
                const index = Math.floor(srcIndex);
                const fraction = srcIndex - index;

                if (index + 1 < mergedAudio.length) {
                    resampled[i] = mergedAudio[index] * (1 - fraction) + mergedAudio[index + 1] * fraction;
                } else {
                    resampled[i] = mergedAudio[index];
                }
            }

            // è½¬æ¢ä¸º 16-bit PCM
            const pcmData = floatTo16BitPCM(resampled);

            // è·å– token å¹¶è¯†åˆ«
            const accessToken = await getBaiduAccessToken();
            const result = await recognizeSpeech(pcmData, accessToken);

            if (result && onResultCallbackRef.current) {
                // å®æ—¶æ›´æ–°è¯†åˆ«ç»“æœ
                onResultCallbackRef.current(result);
            }

            // æ›´æ–°å·²å¤„ç†çš„ç´¢å¼•
            lastProcessedIndexRef.current = totalChunks;
        } catch (error) {
            console.error('åˆ†æ®µè¯†åˆ«å¤±è´¥:', error);
            // åˆ†æ®µè¯†åˆ«å¤±è´¥ä¸å¼¹çª—ï¼Œé¿å…æ‰“æ–­ç”¨æˆ·
        }
    }, []);

    // å¤„ç†å½•éŸ³æ•°æ®çš„å‡½æ•°ï¼ˆæœ€ç»ˆå¤„ç†ï¼‰
    const processRecording = useCallback(async () => {
        if (!audioChunksRef.current.length) {
            console.log('æ— å½•éŸ³æ•°æ®');
            return;
        }

        // æ‰§è¡Œæœ€åä¸€æ¬¡å®Œæ•´è¯†åˆ«
        await processCurrentSegment(false);
    }, [processCurrentSegment]);

    // å¼€å§‹å½•éŸ³
    const startListening = useCallback(async (onResult) => {
        if (isListening) return;

        onResultCallbackRef.current = onResult;
        audioChunksRef.current = [];
        lastProcessedIndexRef.current = 0;

        try {
            // è¯·æ±‚éº¦å…‹é£æƒé™
            const stream = await navigator.mediaDevices.getUserMedia({
                audio: {
                    channelCount: 1,
                    echoCancellation: true,
                    noiseSuppression: true,
                    autoGainControl: true,
                    sampleRate: 48000
                }
            });

            streamRef.current = stream;
            setIsListening(true);

            // ä½¿ç”¨ AudioContext ç›´æ¥å½•åˆ¶
            const audioContext = new (window.AudioContext || window.webkitAudioContext)();
            const source = audioContext.createMediaStreamSource(stream);
            const processor = audioContext.createScriptProcessor(4096, 1, 1);

            audioContextRef.current = audioContext;
            processorRef.current = processor;
            sourceRef.current = source;
            actualSampleRateRef.current = audioContext.sampleRate;

            console.log('ğŸ¤ å¼€å§‹å½•éŸ³ï¼ˆå®æ—¶è¯†åˆ«æ¨¡å¼ï¼‰ï¼Œå®é™…é‡‡æ ·ç‡:', audioContext.sampleRate, 'Hz');
            console.log('ğŸ’¡ æ¯3ç§’è‡ªåŠ¨è¯†åˆ«ä¸€æ¬¡ï¼Œæœ€é•¿30ç§’ï¼Œå¯éšæ—¶ç‚¹å‡»æŒ‰é’®åœæ­¢');

            processor.onaudioprocess = (e) => {
                if (streamRef.current) {
                    const inputData = e.inputBuffer.getChannelData(0);
                    audioChunksRef.current.push(new Float32Array(inputData));
                }
            };

            source.connect(processor);
            processor.connect(audioContext.destination);

            // å¯åŠ¨åˆ†æ®µè¯†åˆ«å®šæ—¶å™¨ï¼ˆæ¯3ç§’è¯†åˆ«ä¸€æ¬¡ï¼‰
            segmentIntervalRef.current = setInterval(() => {
                processCurrentSegment(true);
            }, 3000);

            // 30ç§’åè‡ªåŠ¨åœæ­¢
            timeoutRef.current = setTimeout(() => {
                console.log('â±ï¸ å·²è¾¾åˆ°30ç§’æœ€å¤§å½•éŸ³æ—¶é•¿ï¼Œè‡ªåŠ¨åœæ­¢');
                stopListening();
            }, 30000);

        } catch (error) {
            console.error('å¯åŠ¨å½•éŸ³å¤±è´¥:', error);
            setIsListening(false);

            if (error.name === 'NotAllowedError') {
                alert('âŒ éº¦å…‹é£æƒé™è¢«æ‹’ç»\n\nè¯·åœ¨æµè§ˆå™¨åœ°å€æ å·¦ä¾§ç‚¹å‡»é”å›¾æ ‡ï¼Œå…è®¸ä½¿ç”¨éº¦å…‹é£');
            } else if (error.name === 'NotFoundError') {
                alert('æœªæ‰¾åˆ°éº¦å…‹é£è®¾å¤‡ï¼Œè¯·æ£€æŸ¥éº¦å…‹é£è¿æ¥');
            } else {
                alert(`å¯åŠ¨è¯­éŸ³è¯†åˆ«å¤±è´¥: ${error.message}\nè¯·é‡è¯•æˆ–æ‰‹åŠ¨è¾“å…¥`);
            }
        }
    }, [isListening, processCurrentSegment]);

    // åœæ­¢å½•éŸ³
    const stopListening = useCallback(async () => {
        if (!isListening) return;

        console.log('ğŸ›‘ åœæ­¢å½•éŸ³');

        // æ¸…é™¤è¶…æ—¶
        if (timeoutRef.current) {
            clearTimeout(timeoutRef.current);
            timeoutRef.current = null;
        }

        // æ¸…é™¤åˆ†æ®µè¯†åˆ«å®šæ—¶å™¨
        if (segmentIntervalRef.current) {
            clearInterval(segmentIntervalRef.current);
            segmentIntervalRef.current = null;
        }

        // åœæ­¢å¤„ç†å™¨
        if (processorRef.current) {
            processorRef.current.disconnect();
            processorRef.current = null;
        }

        // åœæ­¢éŸ³é¢‘æº
        if (sourceRef.current) {
            sourceRef.current.disconnect();
            sourceRef.current = null;
        }

        // åœæ­¢éŸ³é¢‘æµ
        if (streamRef.current) {
            streamRef.current.getTracks().forEach(track => track.stop());
            streamRef.current = null;
        }

        setIsListening(false);

        // å¤„ç†æœ€åçš„å½•éŸ³æ•°æ®
        await processRecording();

        // å…³é—­éŸ³é¢‘ä¸Šä¸‹æ–‡
        if (audioContextRef.current) {
            audioContextRef.current.close();
            audioContextRef.current = null;
        }

        // é‡ç½®çŠ¶æ€
        lastProcessedIndexRef.current = 0;
    }, [isListening, processRecording]);

    return {
        isListening,
        startListening,
        stopListening,
        isSecureContext: true,
        hasSupport
    };
};
